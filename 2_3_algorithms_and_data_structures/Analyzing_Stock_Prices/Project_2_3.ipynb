{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing Stock Prices\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this guided project, we'll work with stock market data that was downloaded from [Yahoo Finance](https://finance.yahoo.com/) using the [yahoo_finance](https://pypi.python.org/pypi/yahoo-finance) Python package. This data consists of the daily stock prices from _2007-1-1_ to _2017-04-17_ for several hundred stock symbols traded on the [NASDAQ](http://www.nasdaq.com/) stock exchange, stored in the prices folder. The **download_data.py** script in the same folder as the Jupyter notebook was used to download all of the stock price data. Each file in the prices folder is named for a specific stock symbol, and contains the:\n",
    "- **date** -- date that the data is from.\n",
    "- **close** -- the closing price on that day, which is the price when the trading day ends.\n",
    "- **open** -- the opening price on that day, which is the price when the trading day starts.\n",
    "- **high** -- the highest price the stock reached during trading.\n",
    "- **low** -- the lowest price the stock reached during trading.\n",
    "- **volume** -- the number of shares that were traded during the day.\n",
    "\n",
    "The prices are sorted in ascending order by day. Stock trading doesn't happen on certain days, like weekends and holidays, so there are gaps between days -- we only have data for days on which trading happening.\n",
    "\n",
    "To read in and store all of the data, we'll need several layers of indices:\n",
    "- **Layer 1** -- the stock symbol, or an numeric index representing the stock symbol.\n",
    "- **Layer 2** -- the rows in a stock symbol csv file.\n",
    "- **Layer 3** -- The column names in a stock symbol csv file.\n",
    "\n",
    "A good choice to structure the data could be:\n",
    "- **Hash table** for Layer 1 (stock symbol)\n",
    "- **Hash table** for Layer 2 (columns)\n",
    "- **List** for Layer 3 (rows)\n",
    "\n",
    "## Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import concurrent.futures\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "from statistics import mean\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading files\n",
    "\n",
    "We will read all the files save the information as:\n",
    "1. Dictionaries of stocks (stock name is the key parameter).\n",
    "2. Each stock is a dictionary, where keys are the different column names in the dataset.\n",
    "3. Inside column dictionaries there is the list of values (chronologically sorted, as in the dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filepath):\n",
    "    with open(filepath, 'r') as f:\n",
    "        data = f.read().strip()\n",
    "    key = filepath.replace(\".csv\", \"\").replace(\"my_datasets/prices/\", \"\")\n",
    "    data = data.split(\"\\n\")\n",
    "    data = [d.split(\",\") for d in data][1:]\n",
    "    data_dict = get_data_dict(data)\n",
    "    return key, data_dict\n",
    "\n",
    "def get_data_dict(data):\n",
    "    columns = ['date', 'close', 'open', 'high', 'low', 'volume']\n",
    "    types = [\"date\",\"float\",\"float\",\"float\",\"float\",\"int\"]\n",
    "    data_dict = {}\n",
    "    for i, name in enumerate(columns):\n",
    "        if types[i] == \"date\":\n",
    "            data_dict[name] = [dt.date.fromisoformat(d[i]) for d in data]\n",
    "        elif types[i] == \"float\":\n",
    "            data_dict[name] = [float(d[i]) for d in data]\n",
    "        elif types[i] == \"int\":\n",
    "            data_dict[name] = [int(d[i]) for d in data]\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiprocess not available in W10\n",
    "# results = []\n",
    "# pool = concurrent.futures.ProcessPoolExecutor(max_workers=2)\n",
    "# filepaths = [\"my_datasets/prices/{}\".format(f) for f in os.listdir(\"my_datasets/prices\")]\n",
    "# prices = pool.map(read_file, filepaths)\n",
    "# prices = list(prices)\n",
    "# prices = dict(prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepaths = [\"my_datasets/prices/{}\".format(f) for f in os.listdir(\"my_datasets/prices\")]\n",
    "prices = dict([read_file(f) for f in filepaths])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing aggregates\n",
    "\n",
    "- Computing the **average of closing values** for each stock:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_closing = {}\n",
    "for key, val in prices.items():\n",
    "    avg_closing[key] = mean(val[\"close\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As dictionaries cannot be sorted, we can convert it to list of tuples \"(key, value)\" and sort it by value parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('amzn', 275.1340775710425),\n",
       " ('aapl', 257.1765404023166),\n",
       " ('cme', 230.29466011003862),\n",
       " ('atri', 228.38977615984555),\n",
       " ('fcnca', 200.2524827814672)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_closing_tuples = sorted([(k,v) for k,v in avg_closing.items()], key = lambda x: x[1], reverse=True)\n",
    "#Top5 of highest average closing values\n",
    "avg_closing_tuples[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Computing the **average volumes** for each stock:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('aapl', 130112422.35521236),\n",
       " ('csco', 45224781.428571425),\n",
       " ('cmcsa', 34337459.69111969),\n",
       " ('ebay', 29059822.548262548),\n",
       " ('amd', 24757016.94980695)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_volume = {}\n",
    "for key, val in prices.items():\n",
    "    avg_volume[key] = mean(val[\"volume\"])\n",
    "    \n",
    "#We can create a list of tuples again    \n",
    "avg_volume_tuples = sorted([(k,v) for k,v in avg_volume.items()], key = lambda x: x[1], reverse=True)\n",
    "\n",
    "#Top5 of highest average volumes\n",
    "avg_volume_tuples[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The **average difference between the opening price and the closing price** for each stock:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cme', 3.6001273864864864),\n",
       " ('bidu', 3.5598418084942085),\n",
       " ('amzn', 3.1338533413127414),\n",
       " ('aapl', 2.860417226640927),\n",
       " ('atri', 2.718297284942085)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_daily_diff = {}\n",
    "for key, val in prices.items():\n",
    "    avg_daily_diff[key] = mean([abs(o-c) for o,c in zip(val[\"open\"], val[\"close\"])])\n",
    "    \n",
    "#We can create a list of tuples again    \n",
    "avg_daily_diff_tuples = sorted([(k,v) for k,v in avg_daily_diff.items()], key = lambda x: x[1], reverse=True)\n",
    "\n",
    "#Top5 of highest average daily variations\n",
    "avg_daily_diff_tuples[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding The Most Traded Stock Each Day\n",
    "\n",
    "Now that we've computed some aggregates, we can work on finding the most traded stock each day. We'll need to create a data structure that stores the dates and the stock symbols that were the most traded on that day. \n",
    "\n",
    "In order to find this, we'll need to combine the volume for each stock on each day, and the stock symbol, then sort the volume in descending order.\n",
    "\n",
    "We can create a structure of:\n",
    "- Dictionary with date as key\n",
    "- Tuples with company and volume (company, volume) in the specific date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create structure in a dictionary with date as key\n",
    "trades = {}\n",
    "\n",
    "for key, val in prices.items():\n",
    "    for i, date in enumerate(val[\"date\"]):\n",
    "        if date not in trades:\n",
    "            trades[date]=[]\n",
    "        trades[date].append((key,val[\"volume\"][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the stock with highest volume for each date\n",
    "most_traded = []\n",
    "\n",
    "for key, val in trades.items():\n",
    "    sorted_trades = sorted(val, key= lambda x: x[1], reverse=True)\n",
    "    most_traded.append((key,sorted_trades[0][0]))\n",
    "    \n",
    "most_traded = sorted(most_traded, key= lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(datetime.date(2007, 1, 3), 'aapl'),\n",
       " (datetime.date(2007, 1, 4), 'aapl'),\n",
       " (datetime.date(2007, 1, 5), 'aapl'),\n",
       " (datetime.date(2007, 1, 8), 'aapl'),\n",
       " (datetime.date(2007, 1, 9), 'aapl')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_traded[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searching For High Volume Days\n",
    "\n",
    "Let's say we want to search for transactions in a list on a specific date. We can use a binary or a linear search for this, but binary search will be faster if we want to do repeated searches.\n",
    "\n",
    "Let's search for all transactions on days with unusually high volume. In order to do this, we'll need to:\n",
    "- Compute total volume of trading for each day\n",
    "- Sort and find the 10 highest volume days overall\n",
    "- Find all prices for all stocks on each of the high volume days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(datetime.date(2008, 1, 23), 1964583900),\n",
       " (datetime.date(2008, 10, 10), 1770266900),\n",
       " (datetime.date(2007, 7, 26), 1611272800),\n",
       " (datetime.date(2008, 10, 8), 1599183500),\n",
       " (datetime.date(2008, 1, 22), 1578877700),\n",
       " (datetime.date(2008, 2, 7), 1559032100),\n",
       " (datetime.date(2008, 9, 29), 1555072400),\n",
       " (datetime.date(2007, 11, 8), 1553880500),\n",
       " (datetime.date(2008, 1, 16), 1536176400),\n",
       " (datetime.date(2008, 1, 24), 1533363200)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_volume_per_days = []\n",
    "\n",
    "for key, val in trades.items():\n",
    "    total_volume = sum([x[1] for x in val])\n",
    "    total_volume_per_days.append((key, total_volume))\n",
    "\n",
    "top_10_days_w_volume = sorted(total_volume_per_days, key= lambda x: x[1], reverse=True)[:10]\n",
    "top_10_days_w_volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[datetime.date(2008, 1, 23),\n",
       " datetime.date(2008, 10, 10),\n",
       " datetime.date(2007, 7, 26),\n",
       " datetime.date(2008, 10, 8),\n",
       " datetime.date(2008, 1, 22),\n",
       " datetime.date(2008, 2, 7),\n",
       " datetime.date(2008, 9, 29),\n",
       " datetime.date(2007, 11, 8),\n",
       " datetime.date(2008, 1, 16),\n",
       " datetime.date(2008, 1, 24)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_10_days = [x[0] for x in top_10_days_w_volume]\n",
    "top_10_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_search(array, value):\n",
    "    m = 0\n",
    "    i = 0\n",
    "    z = len(array) - 1\n",
    "    while i <= z:\n",
    "        m = int(i + ((z-i)/2))\n",
    "        if array[m] == value:\n",
    "            return m\n",
    "        elif array[m] < value:\n",
    "            i = m + 1\n",
    "        elif array[m] > value:\n",
    "            z = m - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_day_row(key, index):\n",
    "    row = []\n",
    "    for k,v in prices[key].items():\n",
    "        row.append((k, v[index]))\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('date', datetime.date(2008, 1, 23)),\n",
       "  ('close', 139.070005),\n",
       "  ('open', 136.190006),\n",
       "  ('high', 140.0),\n",
       "  ('low', 126.140003),\n",
       "  ('volume', 843242400)],\n",
       " [('date', datetime.date(2008, 10, 10)),\n",
       "  ('close', 96.799999),\n",
       "  ('open', 85.699999),\n",
       "  ('high', 99.999999),\n",
       "  ('low', 85.000003),\n",
       "  ('volume', 554824900)],\n",
       " [('date', datetime.date(2007, 7, 26)),\n",
       "  ('close', 146.000004),\n",
       "  ('open', 145.910002),\n",
       "  ('high', 148.499994),\n",
       "  ('low', 136.959997),\n",
       "  ('volume', 546657300)],\n",
       " [('date', datetime.date(2008, 10, 8)),\n",
       "  ('close', 89.789999),\n",
       "  ('open', 85.909997),\n",
       "  ('high', 96.330002),\n",
       "  ('low', 85.679998),\n",
       "  ('volume', 551935300)],\n",
       " [('date', datetime.date(2008, 1, 22)),\n",
       "  ('close', 155.639997),\n",
       "  ('open', 148.059998),\n",
       "  ('high', 159.980003),\n",
       "  ('low', 146.000004),\n",
       "  ('volume', 608688500)],\n",
       " [('date', datetime.date(2008, 2, 7)),\n",
       "  ('close', 121.239998),\n",
       "  ('open', 119.969995),\n",
       "  ('high', 124.779999),\n",
       "  ('low', 117.27),\n",
       "  ('volume', 520832900)],\n",
       " [('date', datetime.date(2008, 9, 29)),\n",
       "  ('close', 105.259999),\n",
       "  ('open', 119.620001),\n",
       "  ('high', 119.680002),\n",
       "  ('low', 100.589999),\n",
       "  ('volume', 655514300)],\n",
       " [('date', datetime.date(2007, 11, 8)),\n",
       "  ('close', 175.469997),\n",
       "  ('open', 186.67),\n",
       "  ('high', 186.900005),\n",
       "  ('low', 167.769995),\n",
       "  ('volume', 472594500)],\n",
       " [('date', datetime.date(2008, 1, 16)),\n",
       "  ('close', 159.639996),\n",
       "  ('open', 165.230003),\n",
       "  ('high', 169.009996),\n",
       "  ('low', 156.699995),\n",
       "  ('volume', 553461300)],\n",
       " [('date', datetime.date(2008, 1, 24)),\n",
       "  ('close', 135.600006),\n",
       "  ('open', 139.99),\n",
       "  ('high', 140.700003),\n",
       "  ('low', 132.010004),\n",
       "  ('volume', 501466700)]]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high_volume_days = {}\n",
    "\n",
    "for key, val in prices.items():\n",
    "    for day in top_10_days:\n",
    "        ind = binary_search(val[\"date\"], day)\n",
    "        if ind is None:\n",
    "            continue\n",
    "        if key not in high_volume_days:\n",
    "            high_volume_days[key] = []\n",
    "        high_volume_days[key].append(get_day_row(key,ind))\n",
    "        \n",
    "high_volume_days[\"aapl\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Profitable Stocks\n",
    "\n",
    "Now that we've done some basic analysis, let's see which stocks would have been the most profitable to buy on 2007-01-03. We can do this by:\n",
    "- Subtracting the initial price (first day in dataset) from the final price (last day in dataset), then computing a percentage relative to the initial price. This will tell us how much our initial investment would have grown or shrunk.\n",
    "- Sorting all of the percentages.\n",
    "- Finding the stock that grew the most in the time period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('admp', 7483.8389225948395),\n",
       " ('adxs', 4461.111111111112),\n",
       " ('arcw', 3898.60048982856),\n",
       " ('blfs', 2799.9585720203995),\n",
       " ('amzn', 2231.928619441572),\n",
       " ('anip', 1681.8998622293218),\n",
       " ('apdn', 1549.6700659868025),\n",
       " ('cui', 1525.1625162516252),\n",
       " ('axgn', 1502.7397260273972),\n",
       " ('bcli', 1449.9225038748066)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profits = []\n",
    "\n",
    "for key, val in prices.items():\n",
    "    percentage = ((val[\"close\"][-1] - val[\"open\"][0]) / val[\"open\"][0]) * 100\n",
    "    profits.append((key,percentage))\n",
    "    \n",
    "profits = sorted(profits, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "profits[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most profitable stock to buy in 2007 would have been ADMP, which has increased a 7483% since the first day (03/01/2007)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
